# Ollama

Once the container is running, add/run llama models with following command where last argument is the name of model. Furthur info: https://ollama.com/library
```
docker exec -it ollama ollama run llama3
```
